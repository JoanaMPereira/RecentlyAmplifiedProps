# Recently amplified propellers

This repository keeps the scripts and data used to identify, at large-scale, recently amplified beta-propellers accross the tree of life.

## Content

There are 2 folders:

 - Code: Contains the python scripts used to prepare the seeds, preform and process the searches, validate and annotate the matches, and search for propeller remnants in intergenic regions
 - Data: Contains the data compiled

## The main different scripts

***1. ```overall_analysis_of_results.ipynb```***

This jupyter notebook was used for the overall analysis of results. It can be ran locally to produce the numbers, stats and plots in the manuscript. It assumes all nnecessary data files are in the `Data` folder.

### Seed preparation

***1. ```get_propellers_from_ecod.py```***

The script that collects the target folds from the ECOD database, extracts their full-lenght sequennces, and identifies and extracts their blades. 

External tools required to run it:
 - CESymm (https://github.com/rcsb/symmetry/blob/master/symmetry-tools/docs/CeSymm.md)

Special python modules:
 - matplotlib

Input file:
 - an ecod table (e.g., `ecod.latest.F70.domains.txt`)

Please edit the paths to these tools and the input file in the script.

***2. ```select_propeller_clusters_representatives.py```***

This script takes a sequence cluster map in CLANS format with defined groups and the .json file as generated by the previous script, and selects a representative for each group.

Special python modules:
 - matplotlib
 - pandas
 - numpy

Input file:
 - a clans file (e.g., `selected_full_sequences_from_ecod.latest.F70_f_name_t_name_Coverage_Number_blades_Length.clans`)
 - the json file generated by the previous script (e.g., `ecod.latest.F70_selected_propellers_manually_curated.json`)

Please edit the paths to these tools and the input file in the script.

It generates a fasta file for each propeller that lists the individual blades. These fasta files can then be used for the searches.

### Sequence searches

***1. ```run_searches_for_all_representatives.py```***

This script takes as input a folder with input fasta files and a list of databases to be searched, and fires the `wrap_searches.py` script, which is the main script that performs the searches. 

External tools required to run it:
 - psiblast (its path has to be provided in the `run_psiblast_for_fasta.py` script)
 - nr databases (its path has to be provided in the `run_psiblast_for_fasta.py` script)
 - hhalign (its path has to be provided in the `search_missing_blades.py` script)
 - hhmake (its path has to be provided in the `search_missing_blades.py` script)
 - muscle (its path has to be provided in the `search_missing_blades.py` script)
 - trimal (its path has to be provided in the `search_missing_blades.py` and `select_relevannt_sequences.py` scripts)

Special python modules:
 - argparse
 - numpy
 - biopython
 - matplotlib
 - pandas
 - seaborn
 - pylab
 - pyPDBeREST
 - scipy

To run it, the databases have to be made available locally. The input is the name of the database (e.g., `nr_bac`) and their full path must be set in the `run_psiblast_for_fasta.py` script

This will generate a set of files for each input propeller, which can be concatenated for further analysis with `process_searches_for_all_representatives.py`

***2. ```process_searches_for_all_representatives.py```***

This script takes the folder with the output of `run_searches_for_all_representatives.py` and merges them.
No external tools or special python modules are required.

### Validation and annotation

***1. ```propeller_validation_with_hhrepid.py```***

This script takes the fasta file of full-length sequences generated by `process_searches_for_all_representatives.py` and compares the preliminary annotated highly repeptitive propellers found with the repeats identified by running HHrepID.

External tools required to run it:
 - hhrepid (its path, as well as that of the callibration hmm, has to be provided in the header)

Special python modules:
 - argparse
 - numpy
 - pandas
 - scipy

***2. ```greedy_iterative_annotation_of_domains.py```***

This script allows for the iterative annotation of domains in a set of input sequences using hhsearch.

External tools required to run it:
 - hhsearch (the path must be provided in the header)

Special python modules:
 - argparse
 - numpy

 It requires as input the name of a database. For that, the database needs to be available locally and its location must be provided in the header of the code too. 

 ***3. ```assign_ecod_to_propeller.py```***

This script takes as input the results from runnning the previous one for the set of repetitive propellers found and decides on the fammily they belong to based on the annotations. It does not rely on specific external tools or especial python packages.

### Remnant searches

***1. ```collect_genome_assemblies_for_fasta.py```***

Given the fasta file with the full-length host sequences, this script searches and maps them to a genome assembly.

Special python modules:
 - argparse
 - numpy
 - pandas
 - seaborn
 - biopython
 - requests
 - urlib
 - ast

The output is a table of assemblies that lists the entrezIDs with detected highly repeptitive propellers.

***2. ```find_propeller_graveyards_in_genomes.py```***

This script takes the table generated by `collect_genome_assemblies_for_fasta.py` and searches for putative propeller matches (aka remnants or graveyards) in non-coding intergenic regions flanking the contained entrezIDs.

External tools required to run it:
 - `greedy_iterative_annotation_of_domains.py` (the path must be provided in the header and needs the ECOD database)

Special python modules:
 - argparse
 - numpy
 - urlib
 - requests
 - matplotlib
 - pandas
 - seaborn
 - biopython

The output is the input table including information about the graveyards found as well as a .json file with detailed information about them.
